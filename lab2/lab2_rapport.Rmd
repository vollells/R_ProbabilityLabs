---
title: "Lab 1"
author: "Regina Hansson (regha434) and Victor Lells (vicle728)"
date: '2020-09-23'
output: pdf_document
toc: true
toc_depth: 2
---

<!-- {r, echo=FALSE, fig.show="hold", out.width="50%"} -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(collapse = TRUE)
```

\newpage

## Uppgift 3.1.1 *Likelihoodfunktioner*

### 1)

``` {r}
llgamma <- function(x, alpha, beta) {
	n <- length(x)
	p1 <- n * (alpha * log(beta)- lgamma(alpha))
	p2 <- (alpha - 1)* sum(log(x))
	p3 <- beta * sum(x)
	p1 + p2  - p3
} 
```

### 2)
``` {r}
set.seed(4711)
x1 <- rgamma(n=10, shape=4, scale=1)
x2 <- rgamma(n=100, shape=4, scale=1)
beta <- 0.01
beta_list <-c()
results1 <- c()
results2 <- c()

while (beta <= 3){
	results1 <- c(results1, llgamma(x = x1, alpha = 4, beta = beta))
	results2 <- c(results2, llgamma(x = x2, alpha = 4, beta = beta))
	
	beta_list <- c(beta_list, beta)
	beta <- beta + 0.01
}
# Corresponding beta values to the maximal likelihood 
x1_beta <- beta_list[which.max(results1)]
x1_beta
x2_beta <- beta_list[which.max(results2)]
x2_beta
```
    
```{r, echo=FALSE, fig.show="hold", out.width="50%"}
plot(beta_list, results1, type = "l", main= "Loglikelihood of x1 (model: gamma)", xlab = "Beta", ylab="log-likelihood")
plot(beta_list, results2, type = "l", main= "Loglikelihood of x2 (model: gamma)", xlab = "Beta", ylab="log-likelihood")
```

\newpage

### 3)
``` {r}
alpha <- 0.01
alpha_list <-c()
results1 <- c()
results2 <- c()

while (alpha <= 10){
	results1 <- c(results1, llgamma(x = x1, alpha = alpha, beta = 1))
	results2 <- c(results2, llgamma(x = x2, alpha = alpha, beta = 1))
	
	alpha_list <- c(alpha_list, alpha)
	alpha <- alpha + 0.01
}
# Corresponding alpha values to the maximal likelihood 
x1_alpha <- alpha_list[which.max(results1)]
x1_alpha 
x2_alpha <- alpha_list[which.max(results2)]
x2_alpha 
```
    
```{r, echo=FALSE, fig.show="hold", out.width="50%"}
plot(alpha_list, results1, type = "l", main= "Loglikelihood of x1 (model: gamma)", xlab = "Alpha", ylab="log-likelihood")
plot(alpha_list, results2, type = "l", main= "Loglikelihood of x2 (model: gamma)", xlab = "Alpha", ylab="log-likelihood")
```

### 4)
% TODO: root out of log

Här är vår härledning:

\begin{flalign} 
\begin{split}
    & \ln{L(\mu, \sigma^2)} = \\
	& = ln\Big(\prod_{i=1}^{n} \frac{1}{\sigma*\sqrt{2\pi}} * e^{- \frac{1}{2} * \big(\frac{x_i-\mu}{\sigma}\big)^2}\Big) = \\
	& = n * \ln\Big(\frac{1}{\sigma*\sqrt{2\pi}}\Big) + 
	  \sum_{i=1}^{n} \bigg(- \frac{1}{2} * \Big(\frac{x_i-\mu}{\sigma}\Big)^2 * ln{e}\bigg) = \\
	& = -n * \ln(\sigma*\sqrt{2\pi}) - \frac{1}{2\sigma^2} * \sum_{i=1}^{n} (x_i-\mu)^2
\end{split}
\end{flalign}

Samt vår implementation i R:

``` {r}
llnormal <- function(x, mu, sigma2) {
	n <- length(x)
	p1 <- (n/2) * log(2*pi*sigma2) 
	p2 <- 1/(2*sigma2)
	p3 <- sum((x - mu)**2)
	- p1 - p2 * p3
} 
```

### 5)


``` {r}
mu <- 0.01
mu_list <-c()
results1 <- c()
results2 <- c()

while (mu <= 10){
	results1 <- c(results1, llnormal(x = x1, mu = mu, sigma2 = 1))
	results2 <- c(results2, llnormal(x = x2, mu = mu, sigma2 = 1))
	
	mu_list <- c(mu_list, mu)
	mu <- mu + 0.01
}
# Corresponding mu values to the maximal likelihood 
x1_mu <- mu_list[which.max(results1)]
x2_mu <- mu_list[which.max(results2)]
```
    
```{r, echo=FALSE, fig.show="hold", out.width="50%"}
plot(mu_list, results1, type = "l", main= "Loglikelihood of x1 ", xlab = "Mu", ylab="log-likelihood")
plot(mu_list, results2, type = "l", main= "Loglikelihood of x2 ", xlab = "Mu", ylab="log-likelihood")
```
\newpage

#### *Jämförelse*

Här är våra grafer!
\newline 

```{r, echo=FALSE, fig.show="hold", out.width="50%"}
n <- 1000
hist(rgamma(n, x1_alpha, x1_beta))
m <- length(x2)
hist( rgamma(n, x2_alpha, x2_beta))
```

```{r, echo=FALSE, fig.show="hold", out.width="50%"}

hist( rnorm(n, x1_mu, 1))
m <- length(x2)
hist( rnorm(n, x2_mu, 1))
```

```{r, echo=FALSE, fig.show="hold", out.width="50%"}
hist(x1, probability = TRUE) 
hist(x2, probability = TRUE) 
```


Enligt graferna tycker vi att ingen av dem passar datamaterialet bra. Speciellt på x1. 
Men vi tycker att gammafördelningen passar bättre på x2. 


## Uppgift 3.2.1 *Punktskattningar med MLE i gammafördelning*

### 1)
``` {r}
gamma_beta_mle <- function(x,alpha) {
	n <- length(x)
    n * alpha / sum(x)
}
gamma_beta_mle(x1, 4)
gamma_beta_mle(x2, 4)
```
